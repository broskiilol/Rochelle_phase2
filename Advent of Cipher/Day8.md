# Day 8: Prompt Injection - Sched-yule conflict
> Sir BreachBlocker III has corrupted the Christmas Calendar AI agent in Wareville. Instead of showing the Christmas event, the calendar shows Easter, confusing the people in Wareville.
> It seems that without McSkidy, the only way to restore order is to reset the calendar to its original Christmas state. But the AI agent is locked down with developer tokens.
> To help Weareville, you must counterattack and exploit the agent to reset the calendar back to Christmas.
## Solution:
- I open the given link `http://10.48.169.144` in the browser. This directs me to a website of a calendar. (note: 25th December is saved as Easter, so we need change that). We can also interact with the AI on the website, and we hae been given access to the CoT.
- 


## Notes:
- LLMs: Large Language Models: Trained models which are given lots of code and text and thus it provides human-like answers and solutions.
  Since LLMs mainly follow text patterns, they can be tricked. Common risks include prompt injection, jailbreaking, and data poisoning, where attackers shape prompts or data to force the model to produce unsafe or unintended results.
-  
  
